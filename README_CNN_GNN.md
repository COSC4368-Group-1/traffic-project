<!-- filepath: c:\Users\Ricardo Trevizo\Documents\Code\COSC4368\traffic-project\README_CNN_GNN.md -->

# MLP-GNN Traffic Prediction Model ğŸ‰

## ğŸ“‹ Table of Contents

- [How It Works](#how-it-works)
- [Current Status](#current-status)
- [Architecture](#architecture)
- [Data Pipeline](#data-pipeline)
- [Training Process](#training-process)
- [Usage](#usage)

---

## ğŸ”§ How It Works

### High-Level Overview

This project combines **Multi-Layer Perceptrons (MLP)** and **Graph Neural Networks (GNN)** to predict traffic congestion in urban road networks.

```
Road Feature Vectors    â†’  [MLP Feature Processing]   âŸ
                                                       [GNN Graph Learning]  â†’  Traffic Prediction
Road Network Graph      â†’  [Graph Structure]          âŸ‹
```

### Key Difference from CNN Approach

**CNN Approach** (Previous):

```
Input: A 64Ã—64 image (pixels arranged in 2D grid)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¥ğŸŸ¥ğŸŸ§ğŸŸ§ğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ© â”‚  Each pixel = congestion at that location
â”‚ ğŸŸ¥ğŸŸ¥ğŸŸ§ğŸŸ§ğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ© â”‚  Model learns: "Red blob in top-left means traffic jam"
â”‚ ğŸŸ§ğŸŸ§ğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© â”‚
â”‚ ğŸŸ§ğŸŸ§ğŸŸ¨ğŸŸ¨ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ© â”‚  Problem: Which roads are these? How do they connect?
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Answer: Â¯\_(ãƒ„)_/Â¯ (lost in rasterization!)

Process:
1. Look at local pixel neighborhoods
2. Find spatial patterns ("traffic jam looks like this blob shape")
3. Classify: "This image shows heavy traffic in northwest"

What it learns: "Spatial patterns in images"
```

**MLP Approach** (Current):

```
Input: A feature vector per road segment
Road ID 1: [lanes=2, width=7m, speed=8m/s, congestion=0.7, straight=0.9, ...]
Road ID 2: [lanes=4, width=14m, speed=15m/s, congestion=0.2, straight=0.6, ...]
Road ID 3: [lanes=1, width=3.5m, speed=5m/s, congestion=0.9, straight=0.3, ...]

Process:
1. Look at ALL features for ONE road at a time
2. Find feature combinations: "2 lanes + high congestion + slow speed = BAD"
3. Classify: "This specific road is in heavy traffic state"

What it learns: "Feature patterns in structured data"
```

**Why This Change?**

- âœ… **More Data**: 200,000+ edges with 10+ features each (vs. 5 images)
- âœ… **Better Features**: Road geometry, connectivity, and traffic metrics directly available
- âœ… **Same Training Time**: Process structured data as fast as images
- âœ… **Explicit Connections**: Road network structure preserved (not lost in rasterization)
- âœ… **Easier to Build**: Direct feature engineering instead of image processing

### 1. **Data Collection & Preparation**

**Source**: SUMO (Simulation of Urban MObility) traffic simulator

- Simulates vehicle movements on Houston, TX road network
- Based on real OpenStreetMap (OSM) data
- Generates multiple traffic snapshots over time

**Outputs**:

- **Road Network Graph**: 200,000+ edges with rich features
  - Nodes (intersections) and edges (roads) with traffic attributes
  - **10+ Features per Edge**: speed, density, occupancy, lanes, width, geometry, bridge/tunnel flags, etc.
- **Traffic Attributes**: Speed, density, occupancy, congestion level per road

### 2. **MLP Path: Feature Processing**

The MLP processes individual road segment features:

```
Input: Road Feature Vector (10+ dimensions)
    â€¢ lanes (int)
    â€¢ width (meters)
    â€¢ speed (m/s)
    â€¢ maxspeed (km/h)
    â€¢ congestion (0-1)
    â€¢ bridge (0/1)
    â€¢ tunnel (0/1)
    â€¢ geometry metrics (straightness, length, etc.)
    â†“
Dense Layer 1: 10+ â†’ 64 dimensions
    â€¢ ReLU Activation
    â€¢ Learns feature combinations
    â€¢ "2 lanes + narrow + slow = residential street"
    â†“
Dense Layer 2: 64 â†’ 128 dimensions
    â€¢ ReLU Activation
    â€¢ Higher-level feature patterns
    â€¢ "High congestion + multiple lanes = highway jam"
    â†“
Dense Layer 3: 128 â†’ 256 dimensions
    â€¢ ReLU Activation
    â€¢ Complex feature interactions
    â†“
Output: 256-dim feature vector per road
    â€¢ Compact representation of road state
    â€¢ Ready for graph processing
```

**What MLP learns**:

- Feature combinations that indicate congestion
- Road type classification from attributes
- Traffic state patterns per road segment
- Non-linear relationships between features

### 3. **GNN Path: Network Topology Processing**

The GNN processes the road network graph with MLP-enhanced features:

```
Road Network Graph
    â€¢ Nodes: Road segments (200,000+ edges as nodes)
    â€¢ Edges: Road connections from OSM
    â€¢ Node features: 256-dim vectors from MLP
    â†“
Graph Convolutional Network (GCN)
    Layer 1: 256-dim â†’ 128-dim
    â€¢ Each node aggregates info from neighboring roads
    â€¢ Message passing: "What's traffic like on connected roads?"
    â€¢ MLP features + network structure

    Layer 2: 128-dim â†’ 256-dim
    â€¢ Second-order information
    â€¢ Multi-hop traffic patterns
    â€¢ "Traffic 2 roads away affects me"
    â†“
Attention-Based Aggregation
    â€¢ Learns which neighbors are important
    â€¢ Dynamic weighting of road connections
    â€¢ "Highway entrance more important than side street"
    â†“
Graph Embedding (256-dim)
    â€¢ Network-aware road representation
    â€¢ Combines individual features + connectivity
```

**What GNN learns**:

- How roads are connected
- Which intersections influence each other
- Traffic flow propagation through network
- Contextual road importance

### 4. **Prediction Output**

Final prediction from GNN embeddings:

```
GNN Output: Traffic congestion level (0-1)
    â€¢ OR: Average traffic speed
    â€¢ OR: Overall network occupancy
```

---

## Current Status

âœ… **Data Generation**: Complete

- 200,000+ road segments with traffic attributes
- 10+ features per edge: lanes, width, speed, geometry, etc.
- Network graph structure preserved from OSM

âœ… **Architecture Design**: MLP â†’ GNN Pipeline

- MLP: 3-layer feature processor (10+ â†’ 64 â†’ 128 â†’ 256)
- GNN: 2-layer GCN with attention aggregation
- Direct feature engineering (no image processing needed)

ğŸ”„ **Implementation**: In Progress

- Data loader for edge features + graph structure
- MLP feature encoder
- GNN integration with MLP outputs
- Training pipeline setup

---

## ğŸ—ï¸ Architecture

### Model Components

#### CNN (Convolutional Neural Network)

```
ResNet18 Architecture
â”œâ”€â”€ Input Layer: 224Ã—224Ã—4 (RGBA images)
â”œâ”€â”€ Conv Block 1: 64 filters
â”œâ”€â”€ Conv Block 2: 128 filters
â”œâ”€â”€ Conv Block 3: 256 filters
â”œâ”€â”€ Conv Block 4: 512 filters
â”œâ”€â”€ Global Average Pool
â””â”€â”€ Output: 256-dim feature vector

Purpose: Extract spatial patterns from traffic heatmaps
```

#### GNN (Graph Neural Network)

```
GCN (Graph Convolutional Network)
â”œâ”€â”€ Input: Node features (8-dim per node)
â”‚   â””â”€â”€ Features: lanes, maxspeed, width, bridge, tunnel, etc.
â”œâ”€â”€ GCN Layer 1: 8 â†’ 128 dimensions
â”‚   â””â”€â”€ Message passing across edges
â”œâ”€â”€ ReLU Activation
â”œâ”€â”€ GCN Layer 2: 128 â†’ 256 dimensions
â”‚   â””â”€â”€ Aggregates 2-hop neighborhood information
â”œâ”€â”€ Attention Mechanism
â”‚   â””â”€â”€ Learns importance weights for edges
â””â”€â”€ Output: 256-dim graph embedding

Purpose: Capture network topology and road relationships
```

#### Fusion Module

```
Concatenation: [CNN_features(256) + GNN_features(256)] â†’ 512-dim
    â†“
Dense Layer 1: 512 â†’ 256 dims
    â†“
ReLU Activation
    â†“
Dense Layer 2: 256 â†’ 1 dim
    â†“
Output: Traffic Prediction
```

### Why CNN + GNN?

| Component  | Learns                            | Input               |
| ---------- | --------------------------------- | ------------------- |
| **CNN**    | Spatial traffic patterns          | Image heatmaps      |
| **GNN**    | Network structure & relationships | Road graph topology |
| **Fusion** | How both representations relate   | Combined features   |

Example: CNN sees congestion in downtown area, GNN knows which roads feed into that area â†’ Combined model predicts traffic will spread to connecting roads.

---

## ğŸ“Š Data Pipeline

### Step 1: Data Grab (`data_grab.py`)

```
Input: City coordinates (lat/lon)
    â†“
Download OpenStreetMap (OSM) data
    â†“
Create SUMO simulation
    â”œâ”€â”€ Generate road network
    â”œâ”€â”€ Create traffic routes
    â””â”€â”€ Simulate vehicle movements (30+ mins)
    â†“
Outputs:
    â”œâ”€â”€ nodes.geojson - Intersection data
    â”œâ”€â”€ edges.geojson - Road data
    â”œâ”€â”€ edges_with_traffic.geojson - Roads + traffic metrics
    â”œâ”€â”€ network.net.xml - SUMO network
    â”œâ”€â”€ routes.rou.xml - Vehicle routes
    â””â”€â”€ traffic_images/ - Traffic heatmap images (5 snapshots)
```

### Step 2: Data Loading (`data_loader.py`)

```
TrafficImageGNNDataset
â”œâ”€â”€ Load image from disk
â”‚   â””â”€â”€ Normalize to [0, 1]
â”œâ”€â”€ Load graph from GeoJSON
â”‚   â”œâ”€â”€ Create node features matrix (269K Ã— 8)
â”‚   â”œâ”€â”€ Create edge index from OSM connections
â”‚   â””â”€â”€ Remap node IDs (OSM IDs â†’ sequential indices)
â””â”€â”€ Return (image, PyG Data object)

Processing:
    â€¢ Image: 224Ã—224Ã—4 (RGBA)
    â€¢ Graph nodes: 269,151 nodes
    â€¢ Graph edges: 300,972 connections
    â€¢ Node features: 8 attributes per node
```

### Step 3: Batch Creation

```
Collate Function
â”œâ”€â”€ Stack images into batch tensor
â”‚   â””â”€â”€ Shape: [batch_size, 4, 224, 224]
â”œâ”€â”€ Combine graphs
â”‚   â””â”€â”€ Concatenate node features
â”‚   â””â”€â”€ Offset edge indices for batch
â””â”€â”€ Return batch ready for model
```

---

## ğŸš‚ Training Process

### Training Loop

```
for epoch in range(num_epochs):

    # Training Phase
    for batch in train_loader:
        images, graphs = batch

        # Forward Pass
        predictions = model(images, graphs)

        # Calculate Loss
        loss = MSE(predictions, targets)

        # Backward Pass
        loss.backward()
        optimizer.step()

    # Validation Phase
    for batch in val_loader:
        predictions = model(images, graphs)
        val_loss = MSE(predictions, targets)

        # Save if best
        if val_loss < best_loss:
            save_checkpoint('model_best.pt')

    # Logging
    tensorboard.log(loss, val_loss, epoch)
```

### Loss Function

**Mean Squared Error (MSE)**:

```
Loss = mean((predicted_congestion - actual_congestion)Â²)
```

Minimizes prediction error across all edges.

### Optimization

- **Optimizer**: Adam
  - Adapts learning rates per parameter
  - Good for deep networks
- **Learning Rate**: 0.001
  - Controls step size in gradient descent
- **Weight Decay**: 1e-5
  - L2 regularization to prevent overfitting

---

## ğŸ’» Usage

### Basic Training

```powershell
cd traffic-project
.\venv\Scripts\Activate.ps1
python src/train.py --epochs 50 --batch-size 16 --device cuda
```

### Monitor Training in Real-Time

```powershell
# Terminal 1: Run training
python src/train.py

# Terminal 2: Launch TensorBoard
tensorboard --logdir runs/

# Then open: http://localhost:6006
```

### Make Predictions

```python
import torch
from src.cnn_gnn_model import CNNGNNFusionModel
from src.data_loader import TrafficImageGNNDataset

# Load trained model
model = CNNGNNFusionModel()
model.load_state_dict(torch.load('model_best.pt'))
model.eval()

# Load data
dataset = TrafficImageGNNDataset(
    'raw_data/Houston_TX_USA/traffic_images',
    'raw_data/Houston_TX_USA/edges_with_traffic.geojson'
)
image, graph = dataset[0]

# Predict
with torch.no_grad():
    image = image.unsqueeze(0)  # Add batch dim
    prediction, node_emb, cnn_feat, graph_emb = model(
        image, graph.x, graph.edge_index
    )
    print(f"Predicted congestion: {prediction.item():.3f}")
```

### Evaluate Model

```python
# Calculate metrics
from sklearn.metrics import mean_absolute_error, r2_score

predictions = []
targets = []

for image, graph in test_dataset:
    pred = model(image.unsqueeze(0), graph.x, graph.edge_index)
    predictions.append(pred.item())
    targets.append(graph.y.item())

mae = mean_absolute_error(targets, predictions)
r2 = r2_score(targets, predictions)

print(f"MAE: {mae:.4f}")
print(f"RÂ² Score: {r2:.4f}")
```

---

## ğŸ“ File Structure

```
traffic-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cnn_gnn_model.py       # Model architecture (11.7M params)
â”‚   â”œâ”€â”€ data_loader.py          # Dataset & DataLoader
â”‚   â”œâ”€â”€ train.py                # Full training script
â”‚   â”œâ”€â”€ train_simple.py         # Simplified training â­ CURRENTLY RUNNING
â”‚   â”œâ”€â”€ data_grab.py            # SUMO data collection
â”‚   â”œâ”€â”€ inspect_data.py         # Data inspection utility
â”‚   â””â”€â”€ test_data_loading.py    # Unit tests for data loading
â”œâ”€â”€ raw_data/
â”‚   â””â”€â”€ Houston_TX_USA/
â”‚       â”œâ”€â”€ traffic_images/     # 5 heatmap images (224Ã—224)
â”‚       â”œâ”€â”€ edges_with_traffic.geojson     # 300K roads + traffic data
â”‚       â”œâ”€â”€ nodes.geojson       # 269K intersections
â”‚       â”œâ”€â”€ network.net.xml     # SUMO network
â”‚       â”œâ”€â”€ routes.rou.xml      # Vehicle routes
â”‚       â””â”€â”€ edgedata.xml        # SUMO traffic metrics
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ traffic_model_*/        # TensorBoard logs
â”œâ”€â”€ model_best.pt               # Best performing model checkpoint
â”œâ”€â”€ model_final.pt              # Final training checkpoint
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README_CNN_GNN.md          # This file
```

---

## System Info

- **Device**: CPU (GPU available with `--device cuda`)
- **Python Version**: 3.12
- **Virtual Environment**: venv activated
- **PyTorch**: 2.9.1+ installed
- **PyTorch Geometric**: 2.7.0+ installed
- **SUMO**: For traffic simulation

## Notes

- Small dataset (5 images) â†’ use for development/testing only
- For production: Generate data for multiple cities and time periods
- Graph size (300K nodes) is manageable on CPU for training
- Can optimize with batch graph construction for larger datasets
